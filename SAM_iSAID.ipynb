{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segment_anything import build_sam, SamAutomaticMaskGenerator\n",
    "from PIL import Image, ImageDraw\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Download the model weights to load them here\n",
    "sam = build_sam(checkpoint=\"sam_vit_h_4b8939.pth\")\n",
    "# sam = sam.to(device)\n",
    "# mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_RGB_segment(result, segmentation_mask, annotation):\n",
    "    result[segmentation_mask] = annotation[segmentation_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "img_dir = 'isaid_segm/val/images/images'\n",
    "image_path_list = glob.glob(os.path.join(img_dir, '*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_patch(mask_generator, image, annotation, result, device):\n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "    for mask in masks:\n",
    "        mask[\"segmentation\"] = torch.tensor(mask[\"segmentation\"]).to(device)\n",
    "        add_RGB_segment(result, mask[\"segmentation\"], annotation)\n",
    "\n",
    "def run(image_path, segpath, mask_generator, device):\n",
    "    image = Image.open(image_path)\n",
    "    image = np.array(image)\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack([image] * 3, axis=2)\n",
    "\n",
    "    file_name = os.path.basename(image_path)\n",
    "    print(file_name)\n",
    "    annotation = Image.open(os.path.join(segpath, file_name))\n",
    "    annotation = np.array(annotation)\n",
    "    annotation = torch.tensor(annotation).to(device)\n",
    "    # display(annotation)\n",
    "\n",
    "    result = torch.zeros_like(annotation).to(device)\n",
    "    \n",
    "    step = 800\n",
    "    for h_start in range(0, image.shape[0], step):\n",
    "        for w_start in range(0, image.shape[1], step):\n",
    "            h_end = np.min([h_start+step, image.shape[0]])\n",
    "            w_end = np.min([w_start+step, image.shape[1]])\n",
    "            print(h_start, h_end, w_start, w_end)\n",
    "            update_patch(mask_generator, image[h_start:h_end, w_start:w_end], \n",
    "                         annotation[h_start:h_end, w_start:w_end], result[h_start:h_end, w_start:w_end], device)\n",
    "\n",
    "    if not os.path.exists(segpath+'_fixed'):\n",
    "        os.mkdir(segpath+'_fixed')\n",
    "    Image.fromarray(result.cpu().numpy()).save(os.path.join(segpath+'_fixed', file_name))\n",
    "\n",
    "def run_list(image_path_list, segpath, mask_generator, device):\n",
    "    for image_path in image_path_list:\n",
    "        run(image_path, segpath, mask_generator, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run_list' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m workers \u001b[39m=\u001b[39m [multiprocessing\u001b[39m.\u001b[39mProcess(\n\u001b[1;32m     14\u001b[0m                     target\u001b[39m=\u001b[39mrun_list,\n\u001b[1;32m     15\u001b[0m                     args\u001b[39m=\u001b[39m(new_image_path_list[i], segpath, mask_generator_list[i], torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i))))\n\u001b[1;32m     16\u001b[0m                 \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m8\u001b[39m)]\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m worker \u001b[39min\u001b[39;00m workers:\n\u001b[0;32m---> 20\u001b[0m     worker\u001b[39m.\u001b[39;49mstart()\n",
      "File \u001b[0;32m/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m/data/zxl/miniconda3/envs/CLIP-SAM/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import multiprocessing\n",
    "\n",
    "segpath = \"farsegResultWithThreshold=0.5\"\n",
    "\n",
    "device_id=[0,1,2,3,4,5,6,7]\n",
    "mask_generator_list=[]\n",
    "for device in device_id:\n",
    "    mask_generator_list.append(SamAutomaticMaskGenerator(sam.to(device)))\n",
    "\n",
    "new_image_path_list = np.array_split(np.array(image_path_list), 8)\n",
    "\n",
    "multiprocessing.set_start_method('spawn')\n",
    "workers = [multiprocessing.Process(\n",
    "                    target=run_list,\n",
    "                    args=(new_image_path_list[i], segpath, mask_generator_list[i], torch.device(\"cuda:\"+str(i))))\n",
    "                for i in range(8)]\n",
    "\n",
    "\n",
    "for worker in workers:\n",
    "    worker.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLIP-SAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
